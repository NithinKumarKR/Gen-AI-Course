{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be4c7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nithi\\Desktop\\GitHub\\Gen-AI-Course\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "import os \n",
    "from langserve import add_routes\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "groq_api_key= os.getenv(\"GROQ_API_KEY\")\n",
    "model = ChatGroq(model= 'moonshotai/kimi-k2-instruct', groq_api_key =groq_api_key)\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "groq_api_key= os.getenv(\"GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a01095eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hey Nithin—great to meet you!  \\n“Chief AI Engineer” is a serious title: are you leading the technical direction for an org, or is it more of a hands-on + architecture role? Either way, I’m guessing you’ve got a long list of things you’d like to automate, optimize, or just get off your plate. What’s top-of-mind for you right now—model ops, team enablement, governance, or something else entirely?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 98, 'prompt_tokens': 41, 'total_tokens': 139, 'completion_time': 0.377026985, 'completion_tokens_details': None, 'prompt_time': 0.010616695, 'prompt_tokens_details': None, 'queue_time': 0.283415535, 'total_time': 0.38764368}, 'model_name': 'moonshotai/kimi-k2-instruct', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bfab2-8c36-7780-89dc-177d028f57c3-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 41, 'output_tokens': 98, 'total_tokens': 139})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages  import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is Nithin and I am Cheif AI Engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a73812f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Doing great—thanks, Nithin.  \\nWhat’s on your plate today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 126, 'total_tokens': 144, 'completion_time': 0.076870412, 'completion_tokens_details': None, 'prompt_time': 0.027403291, 'prompt_tokens_details': None, 'queue_time': 0.286573022, 'total_time': 0.104273703}, 'model_name': 'moonshotai/kimi-k2-instruct', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bfab2-8f60-7441-9aa4-383f03fa6fef-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 126, 'output_tokens': 18, 'total_tokens': 144})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi, My name is Nithin and I am Cheif AI Engineer\"),\n",
    "    AIMessage(content='Hi Nithin—great to meet you.  \\nChief AI Engineer is a serious title: I’ll assume you’re deep in model design, infra decisions, and translating business problems into deployable ML.  \\nWhat’s the hardest trade-off you’re facing right now—latency vs. accuracy, compute budget vs. SOTA performance, or something else entirely?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 41, 'total_tokens': 114, 'completion_time': 0.301709155, 'completion_tokens_details': None, 'prompt_time': 0.010471284, 'prompt_tokens_details': None, 'queue_time': 0.287150437, 'total_time': 0.312180439}, 'model_name': 'moonshotai/kimi-k2-instruct', 'system_fingerprint': 'fp_3312304636', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bf49a-adb1-7c01-a174-01604289d888-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 41, 'output_tokens': 73, 'total_tokens': 114})\n",
    "    ,HumanMessage(content=\"Hi, How are you\"),\n",
    "\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7a0d0d",
   "metadata": {},
   "source": [
    "#  Message History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62c0477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "703add9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "store ={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id  not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history= RunnableWithMessageHistory(model, get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46925d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "config ={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84a5cc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi Nithin! Great to meet you—what can I help you with today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 34, 'total_tokens': 53, 'completion_time': 0.048051339, 'completion_tokens_details': None, 'prompt_time': 0.010406368, 'prompt_tokens_details': None, 'queue_time': 0.283060509, 'total_time': 0.058457707}, 'model_name': 'moonshotai/kimi-k2-instruct', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bfab2-915b-7c33-a5ed-c5b1843c5faa-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 34, 'output_tokens': 19, 'total_tokens': 53})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1  =with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi , My name is nithin\")],\n",
    "    config=config\n",
    ") \n",
    "response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93e20b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Nithin.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1  =with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config=config\n",
    ") \n",
    "response1.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cd9355",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11fe7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate , MessagesPlaceholder\n",
    "\n",
    "prompts = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system','Your are helpfull agent just answer in simple way'),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompts | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e787c291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why don’t scientists trust atoms?\\n\\nBecause they make up everything.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response  = chain.invoke({'messages':[HumanMessage(content=\"Tell me one joke\")]})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cb8b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain , get_session_history)\n",
    "\n",
    "config ={'configurable':{'session_id':\"chat3\"}}\n",
    "\n",
    "res = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Tell me one joke\")] ,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2aa64e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why don’t scientists trust atoms?\\n\\nBecause they make up everything!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a0d5618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate , MessagesPlaceholder\n",
    "\n",
    "prompts = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system','Your are helpfull agent just answer in simple way in this language {language}'),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompts | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef5758ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"ನೀನು ದೀಪವಾದರೆ, ನಾನು ನಿನ್ನ ಬೆಳಕಿನಲ್ಲಿ ಮುಳುಗುವ ಕಾಡು!\"'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response  = chain.invoke({'messages':[HumanMessage(content=\"Tell me one pickline\")],'language':'kannada'})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ad4d628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Are you French? Because \\'Eiffel\\' for you.\"'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain , get_session_history , input_messages_key=\"messages\")\n",
    "\n",
    "config ={'configurable':{'session_id':\"chat4\"}}\n",
    "\n",
    "res = with_message_history.invoke(\n",
    "    {\"messages\" :[HumanMessage(content=\"Tell me one pickup line\")] ,\"language\":'english'},\n",
    "    config=config\n",
    ")\n",
    "res.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a225ed",
   "metadata": {},
   "source": [
    "# 144. Managing the Chat Conversation History Using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e47b1e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nithi\\Desktop\\GitHub\\Gen-AI-Course\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\base.py:328: UserWarning: Using fallback GPT-2 tokenizer for token counting. Token counts may be inaccurate for non-GPT-2 models. For accurate counts, use a model-specific method if available.\n",
      "  return len(self.get_token_ids(text))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are collecting only personal details. Do not ask technical or professional questions.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I enjoy learning new technologies and reading.', additional_kwargs={}, response_metadata={}),\n",
       " SystemMessage(content='Ask about preferred language and communication style.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I prefer English for communication.', additional_kwargs={}, response_metadata={}),\n",
       " SystemMessage(content='Confirm that personal details collection is complete.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Yes, those are my personal details.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage , trim_messages\n",
    "\n",
    "trimmer =  trim_messages(\n",
    "    max_tokens= 70 , \n",
    "    strategy=\"last\", \n",
    "    token_counter=model , \n",
    "    include_system= True , \n",
    "    allow_partial= False, \n",
    "    start_on= \"human\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are collecting only personal details. Do not ask technical or professional questions.\"),\n",
    "    HumanMessage(content=\"My name is Nithilesh.\"),\n",
    "\n",
    "    SystemMessage(content=\"Acknowledge the name and ask for basic personal information.\"),\n",
    "    HumanMessage(content=\"I am 26 years old.\"),\n",
    "\n",
    "    SystemMessage(content=\"Continue collecting personal background details politely.\"),\n",
    "    HumanMessage(content=\"I live in India.\"),\n",
    "\n",
    "    SystemMessage(content=\"Ask about hobbies or interests.\"),\n",
    "    HumanMessage(content=\"I enjoy learning new technologies and reading.\"),\n",
    "\n",
    "    SystemMessage(content=\"Ask about preferred language and communication style.\"),\n",
    "    HumanMessage(content=\"I prefer English for communication.\"),\n",
    "\n",
    "    SystemMessage(content=\"Confirm that personal details collection is complete.\"),\n",
    "    HumanMessage(content=\"Yes, those are my personal details.\")\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd5e7773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I don’t have your name—please share it so I can record it.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 84, 'total_tokens': 101, 'completion_time': 0.066292996, 'completion_tokens_details': None, 'prompt_time': 0.014921051, 'prompt_tokens_details': None, 'queue_time': 0.4151933, 'total_time': 0.081214047}, 'model_name': 'moonshotai/kimi-k2-instruct', 'system_fingerprint': 'fp_05df423bab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bfab2-e905-7b82-88e3-4a9b1e6caee1-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 84, 'output_tokens': 17, 'total_tokens': 101})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages = itemgetter(\"messages\")|trimmer)\n",
    "    |prompts\n",
    "    |model\n",
    ")\n",
    "chain.invoke({\n",
    "    \"messages\":messages + [HumanMessage(content=\"What is my name ??\")],\n",
    "    'language':'English'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ff7cc",
   "metadata": {},
   "source": [
    "# Lets wrap this in the Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5f9efd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If you can read, write, speak, and understand Kannada without much trouble, then yes—you’re good at it.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain ,\n",
    "    get_session_history, \n",
    "    input_messages_key = \"messages\",\n",
    ")\n",
    "\n",
    "config ={'configurable':{'session_id':'chat6'}}\n",
    "\n",
    "res = with_message_history.invoke(\n",
    "    {\"messages\" :[HumanMessage(content=\"I am  good at kannada ?\")] ,\"language\":'english'},\n",
    "    config=config\n",
    ")\n",
    "res.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d813fd",
   "metadata": {},
   "source": [
    "# 145. Working With VectorStore And Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "502b849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Nithilesh is a software engineer who enjoys building AI-powered applications.\",\n",
    "        metadata={\n",
    "            \"source\": \"profile\",\n",
    "            \"type\": \"personal\",\n",
    "            \"author\": \"self\",\n",
    "            \"id\": 1\n",
    "        }\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"He is currently based in India and works with Python and machine learning tools.\",\n",
    "        metadata={\n",
    "            \"source\": \"location_info\",\n",
    "            \"type\": \"personal\",\n",
    "            \"author\": \"self\",\n",
    "            \"id\": 2\n",
    "        }\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"LangChain helps developers build LLM-powered applications using modular components.\",\n",
    "        metadata={\n",
    "            \"source\": \"langchain_docs\",\n",
    "            \"type\": \"technical\",\n",
    "            \"category\": \"framework\",\n",
    "            \"id\": 3\n",
    "        }\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Vector databases store embeddings and enable fast semantic search over large datasets.\",\n",
    "        metadata={\n",
    "            \"source\": \"knowledge_base\",\n",
    "            \"type\": \"technical\",\n",
    "            \"category\": \"database\",\n",
    "            \"id\": 4\n",
    "        }\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Transformers are deep learning models that process sequential data using attention mechanisms.\",\n",
    "        metadata={\n",
    "            \"source\": \"ml_notes\",\n",
    "            \"type\": \"technical\",\n",
    "            \"category\": \"machine_learning\",\n",
    "            \"id\": 5\n",
    "        }\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3e30ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'profile', 'type': 'personal', 'author': 'self', 'id': 1}, page_content='Nithilesh is a software engineer who enjoys building AI-powered applications.'),\n",
       " Document(metadata={'source': 'location_info', 'type': 'personal', 'author': 'self', 'id': 2}, page_content='He is currently based in India and works with Python and machine learning tools.'),\n",
       " Document(metadata={'source': 'langchain_docs', 'type': 'technical', 'category': 'framework', 'id': 3}, page_content='LangChain helps developers build LLM-powered applications using modular components.'),\n",
       " Document(metadata={'source': 'knowledge_base', 'type': 'technical', 'category': 'database', 'id': 4}, page_content='Vector databases store embeddings and enable fast semantic search over large datasets.'),\n",
       " Document(metadata={'source': 'ml_notes', 'type': 'technical', 'category': 'machine_learning', 'id': 5}, page_content='Transformers are deep learning models that process sequential data using attention mechanisms.')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40eb04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_api_key= os.getenv(\"HF_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9454b89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings \n",
    "\n",
    "emb =  HuggingFaceEmbeddings(model_name= \"all-MiniLM-L6-v2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d438ef5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x16651092210>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma.from_documents(documents, embedding= emb )\n",
    "\n",
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "362e4e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='2f4d1da8-a0d2-4c7d-b98f-06f3ca818382', metadata={'author': 'self', 'source': 'profile', 'type': 'personal', 'id': 1}, page_content='Nithilesh is a software engineer who enjoys building AI-powered applications.'),\n",
       " Document(id='3e7f9a01-2547-4347-8527-217b552e5236', metadata={'id': 1, 'type': 'personal', 'source': 'profile', 'author': 'self'}, page_content='Nithilesh is a software engineer who enjoys building AI-powered applications.'),\n",
       " Document(id='8fdff639-d31e-406a-814f-63d60e6080b9', metadata={'type': 'personal', 'source': 'profile', 'id': 1, 'author': 'self'}, page_content='Nithilesh is a software engineer who enjoys building AI-powered applications.'),\n",
       " Document(id='88d226c4-d37a-4160-9cbc-b49acaf5277b', metadata={'id': 1, 'author': 'self', 'source': 'profile', 'type': 'personal'}, page_content='Nithilesh is a software engineer who enjoys building AI-powered applications.')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.similarity_search(\"Who is Nithilesh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03cc1313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='2f4d1da8-a0d2-4c7d-b98f-06f3ca818382', metadata={'source': 'profile', 'author': 'self', 'type': 'personal', 'id': 1}, page_content='Nithilesh is a software engineer who enjoys building AI-powered applications.'),\n",
       " Document(id='3e7f9a01-2547-4347-8527-217b552e5236', metadata={'type': 'personal', 'author': 'self', 'id': 1, 'source': 'profile'}, page_content='Nithilesh is a software engineer who enjoys building AI-powered applications.'),\n",
       " Document(id='8fdff639-d31e-406a-814f-63d60e6080b9', metadata={'source': 'profile', 'id': 1, 'author': 'self', 'type': 'personal'}, page_content='Nithilesh is a software engineer who enjoys building AI-powered applications.'),\n",
       " Document(id='88d226c4-d37a-4160-9cbc-b49acaf5277b', metadata={'author': 'self', 'source': 'profile', 'id': 1, 'type': 'personal'}, page_content='Nithilesh is a software engineer who enjoys building AI-powered applications.')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await vector_store.asimilarity_search(\"Nithilesh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8575268",
   "metadata": {},
   "source": [
    "# Retrivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2b89bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(id='2f4d1da8-a0d2-4c7d-b98f-06f3ca818382', metadata={'id': 1, 'type': 'personal', 'author': 'self', 'source': 'profile'}, page_content='Nithilesh is a software engineer who enjoys building AI-powered applications.')],\n",
       " [Document(id='11572734-8886-4d44-8f68-1e71b74f2154', metadata={'source': 'langchain_docs', 'type': 'technical', 'category': 'framework', 'id': 3}, page_content='LangChain helps developers build LLM-powered applications using modular components.')]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List \n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "ret = RunnableLambda(vector_store.similarity_search).bind(k=1)\n",
    "\n",
    "ret.batch(['Nithin','LangChain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66ba7fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(id='2f4d1da8-a0d2-4c7d-b98f-06f3ca818382', metadata={'author': 'self', 'id': 1, 'source': 'profile', 'type': 'personal'}, page_content='Nithilesh is a software engineer who enjoys building AI-powered applications.')],\n",
       " [Document(id='11572734-8886-4d44-8f68-1e71b74f2154', metadata={'type': 'technical', 'category': 'framework', 'source': 'langchain_docs', 'id': 3}, page_content='LangChain helps developers build LLM-powered applications using modular components.')]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriver = vector_store.as_retriever(\n",
    "    search_type ='similarity',\n",
    "    search_kwargs= {'k':1} ,\n",
    ")\n",
    "\n",
    "retriver.batch(['Nithin','LangChain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eb1d49d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "messages=     \"\"\"\n",
    "Answer the following question based only on the provided context:\n",
    "{question}\n",
    "Context:\n",
    "{context}\n",
    " \"\"\"\n",
    "\n",
    "\n",
    "prompt  =  ChatPromptTemplate.from_messages([(\"human\",messages)])\n",
    "\n",
    "\n",
    "rag_chain = {\"context\":retriver ,'question':RunnablePassthrough()} | prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c1484f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is a framework that helps developers build LLM-powered applications using modular components.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke('langchain').content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5adc173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gen-AI-Course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
